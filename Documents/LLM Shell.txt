Source:
https://app.readytensor.ai/publications/llm-shell-mi7D28yZiwtd
Subject:
LLM Shell
Content:
Zsh Ollama Command Helper
This project enhances your Zsh terminal by allowing you to input natural language queries for shell commands you can't remember. By pressing Ctrl+B, your query is sent to an Ollama model, which generates the appropriate command. The command is displayed, and you're prompted to execute it or not (y/n).

ğŸ® Demo
https://github.com/user-attachments/assets/64c6c2df-d8a4-4360-adcb-b381a0907f18

ğŸ’¡ Simply type your question and press Ctrl+B to get the command you need!

Table of Contents
Features
Prerequisites
Installation
Configuration
Usage
Customization
Troubleshooting
TODO
License
âœ¨ Features
ğŸ—£ï¸ Natural Language Queries
Ask questions in plain English about shell commands

ğŸ¤– Model Integration
Uses your locally running Ollama instance with a finetuned model

âš¡ Command Execution
Shows the generated command and prompts you to execute it

ğŸ”„ Model Selection
Easily switch between different Ollama models

ğŸ¨ Customizable
Adjust colors and default settings to your preference

ğŸ”’ Privacy-Focused
100% local execution - your queries never leave your machine

Prerequisites
Operating System: Unix-like system (Linux, macOS).
Shell: Zsh.
Python: Version 3.11.
Ollama: Installed and running locally.
jq: Command-line JSON processor.
Installation
1. Ensure Prerequisites Are Met
Install Zsh
If you don't have Zsh installed:

# On Ubuntu/Debian
sudo apt update
sudo apt install zsh

# On macOS (using Homebrew)
brew install zsh
Install Python 3.11
# On Ubuntu/Debian
sudo apt update
sudo apt install python3.11 python3.11-venv

# On macOS (using Homebrew)
brew install python@3.11
Install Ollama
Follow the installation instructions from Ollama's official documentation.

Install jq
# On Ubuntu/Debian
sudo apt update
sudo apt install jq

# On macOS (using Homebrew)
brew install jq
2. Run the install.sh Script
./install.sh 
3. Reload Your Zsh Configuration
source ~/.zshrc 
Configuration
Default Ollama Model
The default model is set to vitali87/shell-commands. You can change it by editing the export ZSH_OLLAMA_MODEL line in your ~/.zshrc.

export ZSH_OLLAMA_MODEL="your-preferred-model"
Usage
Ask a Question
Type your natural language query directly into the terminal prompt.

how to list all files modified in the last 24 hours 
Trigger the Helper
Press Ctrl+B to activate the helper.

Example Output:
ğŸ¤” Asking Ollama (using model: vitali87/shell-commands)... 
Your query: how to list all files modified in the last 24 hours 
Generated command: find . -type f -mtime -1 
Execute? [y/N] 
Execute the Command
Press y and hit Enter to execute the command. Press any other key to abort.

Customization
Changing the Model
List Available Models
set_ollama_model 
Set a Different Model
set_ollama_model your_model_name 
Example:
set_ollama_model llama2:7b 
Customizing Colors
The colors can be adjusted by modifying the color codes in the Zsh configuration.

Color Codes:
Black: \e[30m
Red: \e[31m
Green: \e[32m
Yellow: \e[33m
Blue: \e[34m
Magenta: \e[35m
Cyan: \e[36m
White: \e[37m
Reset: \e[0m
Steps:
Open the Zsh configuration file:

nano ~/.zshrc 
Locate the ollama_command_helper function.

Modify the echo statements:

echo -e "\e[33mYour query:\e[0m $user_query" 
echo -e "\e[32mGenerated command:\e[0m $command" 
Replace the color codes with your preferred ones.

Save and exit the editor.

Reload your Zsh configuration:

source ~/.zshrc 
Troubleshooting
Error: No Command Generated
Ensure your Ollama server is running and the specified model is available.

Dependencies Not Found
Make sure Python 3.11 and jq are installed on your system.

Virtual Environment Issues
If you encounter issues with the virtual environment:

Remove the existing virtual environment:

rm -rf ~/.config/zsh/ollama_env 
Re-run the installation script:

./install.sh 
Reload your Zsh configuration:

source ~/.zshrc 
Powerlevel10k Warning
If you see a warning related to Powerlevel10k's instant prompt:

Place the Ollama Command Helper configuration after Powerlevel10k initialization in your ~/.zshrc.

Alternatively, disable the instant prompt feature in Powerlevel10k.

ğŸ“‹ Roadmap & TODO
Progress

ğŸš€ Upcoming Features
User Experience
 ğŸ¨ Add color themes support
 Dark mode
 Light mode
 Terminal-native theme
 âŒ¨ï¸ Customizable keyboard shortcuts
 ğŸ’¾ Command history with search functionality
 ğŸ” Auto-completion suggestions
AI/ML Enhancements
 ğŸ§  Context-aware command suggestions
 ğŸ“Š Learning from user corrections
Performance & Integration
 âš¡ Improve response time
 ğŸ”Œ Plugin system for extensions
 ğŸ“¦ Package for different package managers
 Homebrew
 apt
 pip
ğŸ”„ In Progress
User Feedback System
 Basic feedback collection
 ğŸ‘ Command rating system (thumbs up/down)
 ğŸ“ Feedback submission UI
 ğŸ“Š Analytics dashboard for feedback
Command History Enhancement
 Basic history storage
 ğŸ” Searchable command history
 ğŸ“ˆ Usage statistics
 ğŸ¯ Success/failure tracking
ğŸ¯ Future Goals
Community Features
 ğŸ‘¥ Command sharing platform
 ğŸŒŸ Popular commands repository
 ğŸ¤ Community contributions system
Documentation
 ğŸ“š API documentation
 ğŸ¥ Video tutorials
 ğŸ‘©â€ğŸ’» Developer guide
 ğŸŒ Internationalization
âœ… Completed
 Basic command generation
 Model selection interface
 Installation script
 Basic error handling
Acknowledgments
Ollama for providing the LLM serving platform.

OpenAI for the openai Python package.

Feel free to contribute to this project by submitting issues or pull requests.

ğŸ“Š Project Stats